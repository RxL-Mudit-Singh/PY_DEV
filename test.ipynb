{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cx_Oracle as cx\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdns = cx.makedsn('10.100.22.99','1521',service_name='PVSDEVDB')\n",
    "cnxn = cx.connect(user=r'PVS_DB_55JULY', password='rxlogix', dsn=cdns)\n",
    "c = cnxn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.execute(\"CREATE TABLE TOR_TEST(NAME VARCHAR2(100),AGE NUMBER,LOCATION VARCHAR2(100))\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.execute('Select * from  TOR_TEST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql('Select * from  TOR_TEST',cnxn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "byte_value2={\n",
    "    \"name\": \"xxx\",\n",
    "    \"age\": 22,\n",
    "    \"location\": \"Delhi\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.execute(\"insert into tor_test values('Mudit1',23,'Noida')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.execute(f\"insert into tor_test values({byte_value2['name']},{byte_value2['age']},{byte_value2['location']})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f\"insert into tor_test(name,age,location) values('{byte_value2['name']}','{byte_value2['age']}','{byte_value2['location']}')\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnxn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnxn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vr = pd.read_sql('Select * from pvs_logging where run_id = 44990 order by start_time desc',cnxn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vr.to_csv('C:/DEV/PY_DEV/ouput.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val = 44990\n",
    "S = \"\"\"SELECT * FROM PVS_LOGGING WHERE RUN_ID = :val ORDER BY START_TIME DESC\"\"\"\n",
    "c.execute(S,VAL=val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql(\"\"\"SELECT * FROM PVS_LOGGING WHERE RUN_ID = 44990 ORDER BY START_TIME DESC\"\"\",cnxn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = requests.post(\"http://127.0.0.1:8881/\",data='{\"name\" : \"Abc\" , \"age\" : 22, \"location\" : \"Delhi\"}')\n",
    "# '{\"name\": \"Aditya\", \"age\": 21, \"location\": \"Delhi\"}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flatten_json import  flatten\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def include_keys(dic, keys):\n",
    "#     key_set = set(keys) & set(dic.keys())\n",
    "#     return {key: dic[key] for key in key_set}\n",
    "# def flatten_list(d):\n",
    "#     try:\n",
    "#         key, lst = next((k, v) for k, v in d.items() if isinstance(v, list))\n",
    "#     except (StopIteration, AttributeError):\n",
    "#         return [flatten(d)]\n",
    "#     return [flatten({**d, **{key: v}}) for record in lst for v in flatten_list(record)]\n",
    "# def generate_inserts(table, data):\n",
    "#     jsons = flatten_list(data)\n",
    "#     statements = []\n",
    "#     for i in jsons:\n",
    "#         cols = i.keys()\n",
    "#         values = i.values()\n",
    "#         ins = f\"INSERT INTO {table} ({','.join(cols)}) VALUES ({','.join(['%s']*len(cols))})\"\n",
    "#         statements.append((ins,tuple(values)))\n",
    "#     return statements\n",
    "# def return_all_inserts(dictionary):\n",
    "#     generic_keys = ['tenantId','caseId','versionNum']\n",
    "#     inserts = {}\n",
    "#     for i in dictionary:\n",
    "#         if i not in generic_keys:\n",
    "#             t1 = include_keys(dictionary, generic_keys+[i])\n",
    "#             for j in t1:\n",
    "#                 if isinstance(t1[j],dict):\n",
    "#                     if 'ArrayElem' in t1[j].keys():\n",
    "#                         t1[j] = t1[j]['ArrayElem']\n",
    "#             inserts[i] = generate_inserts(i,t1)\n",
    "#     return inserts\n",
    "\n",
    "# with open('jsons/sample.json','r', encoding=\"utf8\") as fp:\n",
    "#     string = fp.read()\n",
    "#     o = json.loads(string)\n",
    "#     print(return_all_inserts(o))\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('jsons/msg1.json','r', encoding=\"utf8\") as fp:\n",
    "#     string = fp.read()\n",
    "#     o = json.loads(string)\n",
    "#     for i in o.items():\n",
    "#         print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('jsons/msg1.json','r+',encoding='utf-8') as d:\n",
    "#     string = d.read()\n",
    "#     data  = json.loads(string)\n",
    "#     print(type(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from flatten_json import flatten\n",
    "\n",
    "\n",
    "def include_keys(dic, keys):\n",
    "    key_set = set(keys) & set(dic.keys())\n",
    "    return {key: dic[key] for key in key_set}   \n",
    "\n",
    "def flatten_list(d):\n",
    "    try:\n",
    "        key, lst = next((k, v) for k, v in d.items() if isinstance(v, list))\n",
    "    except (StopIteration, AttributeError):\n",
    "        return [flatten(d)]\n",
    "    return [flatten({**d, **{key: v}}) for record in lst for v in flatten_list(record)]\n",
    "def generate_inserts(table, data):\n",
    "    jsons = flatten_list(data)\n",
    "    statements = []\n",
    "    for i in jsons:\n",
    "        cols = i.keys()\n",
    "        values = i.values()\n",
    "        # ins = f\"INSERT INTO {table} ({','.join(cols)}) VALUES ({','.join(['%s']*len(cols))})\"\n",
    "        ins = f\"INSERT INTO {table} ({','.join(cols)}) VALUES {tuple(values)}\"\n",
    "        # statements.append((ins,tuple(values)))\n",
    "        statements.append((ins))\n",
    "    return statements\n",
    "def return_all_inserts(dictionary):\n",
    "    generic_keys = ['tenantId','caseId','versionNum']\n",
    "    inserts = {}\n",
    "    for i in dictionary:\n",
    "        if i not in generic_keys:\n",
    "            t1 = include_keys(dictionary, generic_keys+[i])\n",
    "            for j in t1:\n",
    "                if isinstance(t1[j],dict):\n",
    "                    if 'ArrayElem' in t1[j].keys():\n",
    "                        t1[j] = t1[j]['ArrayElem']\n",
    "            inserts[i] = generate_inserts(i,t1)\n",
    "    return inserts\n",
    "\n",
    "# print(generate_inserts('C_AE_IDENTIFICATION',x))\n",
    "\n",
    "with open('jsons/sample.json','r',encoding='utf-8') as X:\n",
    "    string = X.read()\n",
    "    D = json.loads(string)\n",
    "    print(type(D))\n",
    "    print(return_all_inserts(D))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da\n",
    "import numpy as np\n",
    "import dask as d\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = da.ones((10000,10000,10000))\n",
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_json('jsons/tst.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import mod\n",
    "from pathlib import Path\n",
    "\n",
    "def split_file(a,n):\n",
    "    k,m = divmod(len(a),n)\n",
    "    return list((a[i * k + min(i, m):(i + 1) * k + min(i + 1, m)] for i in range(n)))\n",
    "\n",
    "def load(file)->list:\n",
    "    with open(file,mode='rb') as fp:\n",
    "        string = fp.read()\n",
    "        o = json.loads(string)\n",
    "        line_chunk = split_file(o,100)\n",
    "        return line_chunk\n",
    "\n",
    "\n",
    "# print(load('binarydata'))\n",
    "\n",
    "data = Path('binarydata').read_bytes()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from distributed import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inc(x):\n",
    "    return x+1\n",
    "\n",
    "x = Client.submit(inc,10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from dask.distributed import Scheduler, Worker, Client\n",
    "\n",
    "async def f():\n",
    "    async with Scheduler() as s:\n",
    "        async with Worker(s.address) as w1, Worker(s.address) as w2:\n",
    "            async with Client(s.address, asynchronous=True) as client:\n",
    "                future = client.submit(lambda x: x + 1, 10)\n",
    "                result = await future\n",
    "                print(result)\n",
    "\n",
    "asyncio.get_event_loop().run_until_complete(f())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b044e500be76e278f8af992ff09c18d106167691629593a72c8d65315c33d3bf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
